{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniVGGNet:\n",
    "    @staticmethod\n",
    "    def build(width, height, depth, classes):\n",
    "        # initialize model along with input shape to be \"channeÃ´s last\"\n",
    "        model = Sequential()\n",
    "        inputShape = (height, width, depth)\n",
    "        channelDimension = -1                           # -1 = last ordering\n",
    "\n",
    "        # if \"channels first\" update input shape and channels dimension\n",
    "        if K.image_data_format() == \"channels_first\":\n",
    "            inputShape = (depth, height, width)\n",
    "            channelDimension = 1                        # batch normalization operatesover channels - in order to apply\n",
    "                                                        # BN need to know which axis to normalize over, 1 = first order\n",
    "\n",
    "\n",
    "        # first layer - (CONV => RELU => BN) * 2 => POOL => DO\n",
    "        model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape = inputShape))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=channelDimension))\n",
    "\n",
    "        model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape = inputShape))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=channelDimension))\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))    # node from POOL layer will be randomly disconnected from next layer with prob 25%\n",
    "\n",
    "        # second layer - (CONV => RELU => BN) * 2 => POOL => DO\n",
    "        model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=channelDimension))\n",
    "\n",
    "        model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=channelDimension))\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "        # FC => RELU layers\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512))                   # 512 nodes\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.5))                 # increasing probability to 50%\n",
    "\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] -o OUTPUT\n",
      "ipykernel_launcher.py: error: the following arguments are required: -o/--output\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timco/.conda/envs/ml/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3334: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-o\", \"--output\", required=True, help=\"path to the output loss/accuracy plot\")\n",
    "args = vars(ap.parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training and testing data, then scale it into range [0, 1]\n",
    "print(\"[INFO] loading CIFAR-10 data...\")\n",
    "((trainX, trainY), (testX, testY)) = cifar10.load_data()\n",
    "trainX = trainX.astype(\"float\") / 255.0\n",
    "testX = testX.astype(\"float\") / 255.0\n",
    "\n",
    "# convert labels from integers to vectors\n",
    "lab_bin = LabelBinarizer()\n",
    "trainY = lab_bin.fit_transform(trainY)\n",
    "testY = lab_bin.transform(testY)\n",
    "\n",
    "# initialize label names for CIFAR-10 dataset\n",
    "labelNames = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "\n",
    "# initialize optimizer and model\n",
    "print(\"[INFO] compiling model...\")\n",
    "# SGD with learning rate = 0.01, Nestrov accelerated gradient - True\n",
    "# decay - slowly reduce learning rate over time - helpful in reducing overfitting -> higher accuracy, lr/40 - 40 epochs\n",
    "optimizer = SGD(lr=0.01, decay=0.01/40, momentum=0.9, nesterov=True)\n",
    "model = MiniVGGNet.build(width=32, height=32, depth=3, classes=10)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "# train network\n",
    "print(\"[INFO] training network...\")\n",
    "H = model.fit(trainX, trainY, validation_data=(testX, testY), batch_size=64, epochs=40, verbose=1)\n",
    "\n",
    "# evaluate network\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(testX, batch_size=64)\n",
    "print(classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), target_names=labelNames))\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, 40), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, 40), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, 40), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, 40), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on CIFAR-10\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig(args[\"output\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
