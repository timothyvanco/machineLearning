{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Predicting house prices with regression\n",
    "\n",
    "Compare several regression methods by using the same dataset. \n",
    "Try to predict the price of a house as a function of its attributes.\n",
    "\n",
    "As the dataset, use the Boston house-prices dataset, which includes 506 instances, representing houses in the suburbs of Boston by 14 features, one of them (the median value of owner-occupied homes) being the target class (for a detailed reference, see http://archive.ics.uci.edu/ml/datasets/Housing). \n",
    "Each attribute in this dataset is real-valued."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n"
     ]
    }
   ],
   "source": [
    "print(boston.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n",
      " 'B' 'LSTAT']\n"
     ]
    }
   ],
   "source": [
    "print(boston.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  50.0\n",
      "min:  5.0\n",
      "mean:  22.532806324110677\n"
     ]
    }
   ],
   "source": [
    "print(\"max: \", np.max(boston.target))\n",
    "print(\"min: \", np.min(boston.target))\n",
    "print(\"mean: \", np.mean(boston.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(boston.data, boston.target, test_size=0.25, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[33.8 20.3 10.2 22.  21.2 24.2 29.  22.7 21.8 34.9 25.2 20.9 19.4 20.\n 14.  30.1 33.1 20.6 22.6 33.4 20.1 10.5 15.6 16.8 22.6 34.6 19.8 17.8\n 22.  17.4 15.4 16.7 22.6 15.1 21.4 15.3  7.4 13.9 17.6 25.  46.7 17.1\n 23.1 18.7 21.9 18.9 26.7 22.3 25.  14.6 42.8 17.3 22.2 36.5 22.8 19.9\n 36.2 50.  25.  22.2 17.5 23.9 19.6 24.7 28.4  8.7 21.7 20.  19.9 24.5\n 15.   7.  15.2 20.4  8.5 17.1 30.1 15.  19.4 23.2 17.  18.9 50.  25.\n 46.   7.2 17.8 35.1 24.3  5.  16.6 21.8 28.5 22.  20.3 21.7 26.4 30.7\n 50.  17.2 26.6 21.  23.4 19.5 20.7 23.3 48.8 15.6 19.6 17.4 21.7 14.6\n 37.9  9.7 17.8 12.1 20.1 29.9 26.4 18.8 32.5 15.7 13.4 21.7 23.6 11.9\n 13.8 22.2 13.  33.2 50.  22.3 22.4 23.8 29.1 20.8 23.7 19.8 13.9 28.4\n 45.4 23.7 50.  18.  17.1 18.9 10.4 24.7 23.9 23.  20.2  8.5 14.2 20.3\n 18.5 12.  19.3 20.6 16.1 12.3 23.1 22.7 20.3 16.7 27.9 21.4  8.1 37.6\n 15.6 29.6 22.9 24.8 24.4 50.  28.7 50.  16.5 18.2 50.  16.2 14.1 21.2\n 18.4 25.  50.  21.2 20.4 15.2 22.  19.8 22.1 23.9 24.6 23.9 21.7 44.8\n  7.2 18.5 20.1 23.3 19.2 29.1 31.  22.9 27.5 39.8 22.  22.8 22.9 14.3\n 14.5 22.4 19.3 32.  20.1 18.3 24.5 18.4 23.1 22.6 20.2 17.8 31.6 43.5\n 36.4 11.3 20.5 23.2 29.8 20.6 24.3 18.1 19.1 21.4 31.5 19.2 14.3 24.8\n 21.1 18.2 48.3 19.4 21.2 10.9 27.5 34.7 14.4 22.8 17.8 50.  24.4 12.8\n 30.8 28.2 25.  33.1 27.5 12.7 43.1 13.4 21.5 33.4 23.8 21.  26.6 18.5\n 23.  24.1 20.5 32.2 14.4 11.8 19.5 23.7 13.2 29.  18.2 18.6 23.  42.3\n 17.2 16.2 20.  30.3 20.9 20.4 24.8 18.7 16.8 22.5 18.8 23.7 23.8 19.6\n 20.4 16.1 44.  19.3 17.4 10.2 11.7 37.2 11.  23.6 22.8 15.  34.9 17.9\n 24.4 24.5  6.3 29.4 10.4 38.7 20.  19.4 37.  50.  18.7 48.5 35.4 23.4\n  7.  50.  20.7 35.4  9.6 25.1 16.1 27.  16.6 13.3 25.  24.  19.6 29.6\n 21.7 19.1 22.  13.3 27.1 22.9 33.2 13.5 14.5  8.3 41.7 31.2 23.9 23.1\n 24.3 18.3 20.8 28.  19.5 21.5 13.1 12.5 31.7 13.1 23.1 14.5 22.2 13.1\n 37.3 22.  10.2  5.  19.3 16.  18.6 50.  31.6 24.1 15.6 19.4 23.3 23.2\n 13.6].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-e43a32290bee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscalerX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mscalery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscalery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscalery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    661\u001b[0m         X = check_array(X, accept_sparse=('csr', 'csc'), copy=self.copy,\n\u001b[1;32m    662\u001b[0m                         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m                         force_all_finite='allow-nan')\n\u001b[0m\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m         \u001b[0;31m# Even in the case of `with_mean=False`, we update the mean anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    519\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[33.8 20.3 10.2 22.  21.2 24.2 29.  22.7 21.8 34.9 25.2 20.9 19.4 20.\n 14.  30.1 33.1 20.6 22.6 33.4 20.1 10.5 15.6 16.8 22.6 34.6 19.8 17.8\n 22.  17.4 15.4 16.7 22.6 15.1 21.4 15.3  7.4 13.9 17.6 25.  46.7 17.1\n 23.1 18.7 21.9 18.9 26.7 22.3 25.  14.6 42.8 17.3 22.2 36.5 22.8 19.9\n 36.2 50.  25.  22.2 17.5 23.9 19.6 24.7 28.4  8.7 21.7 20.  19.9 24.5\n 15.   7.  15.2 20.4  8.5 17.1 30.1 15.  19.4 23.2 17.  18.9 50.  25.\n 46.   7.2 17.8 35.1 24.3  5.  16.6 21.8 28.5 22.  20.3 21.7 26.4 30.7\n 50.  17.2 26.6 21.  23.4 19.5 20.7 23.3 48.8 15.6 19.6 17.4 21.7 14.6\n 37.9  9.7 17.8 12.1 20.1 29.9 26.4 18.8 32.5 15.7 13.4 21.7 23.6 11.9\n 13.8 22.2 13.  33.2 50.  22.3 22.4 23.8 29.1 20.8 23.7 19.8 13.9 28.4\n 45.4 23.7 50.  18.  17.1 18.9 10.4 24.7 23.9 23.  20.2  8.5 14.2 20.3\n 18.5 12.  19.3 20.6 16.1 12.3 23.1 22.7 20.3 16.7 27.9 21.4  8.1 37.6\n 15.6 29.6 22.9 24.8 24.4 50.  28.7 50.  16.5 18.2 50.  16.2 14.1 21.2\n 18.4 25.  50.  21.2 20.4 15.2 22.  19.8 22.1 23.9 24.6 23.9 21.7 44.8\n  7.2 18.5 20.1 23.3 19.2 29.1 31.  22.9 27.5 39.8 22.  22.8 22.9 14.3\n 14.5 22.4 19.3 32.  20.1 18.3 24.5 18.4 23.1 22.6 20.2 17.8 31.6 43.5\n 36.4 11.3 20.5 23.2 29.8 20.6 24.3 18.1 19.1 21.4 31.5 19.2 14.3 24.8\n 21.1 18.2 48.3 19.4 21.2 10.9 27.5 34.7 14.4 22.8 17.8 50.  24.4 12.8\n 30.8 28.2 25.  33.1 27.5 12.7 43.1 13.4 21.5 33.4 23.8 21.  26.6 18.5\n 23.  24.1 20.5 32.2 14.4 11.8 19.5 23.7 13.2 29.  18.2 18.6 23.  42.3\n 17.2 16.2 20.  30.3 20.9 20.4 24.8 18.7 16.8 22.5 18.8 23.7 23.8 19.6\n 20.4 16.1 44.  19.3 17.4 10.2 11.7 37.2 11.  23.6 22.8 15.  34.9 17.9\n 24.4 24.5  6.3 29.4 10.4 38.7 20.  19.4 37.  50.  18.7 48.5 35.4 23.4\n  7.  50.  20.7 35.4  9.6 25.1 16.1 27.  16.6 13.3 25.  24.  19.6 29.6\n 21.7 19.1 22.  13.3 27.1 22.9 33.2 13.5 14.5  8.3 41.7 31.2 23.9 23.1\n 24.3 18.3 20.8 28.  19.5 21.5 13.1 12.5 31.7 13.1 23.1 14.5 22.2 13.1\n 37.3 22.  10.2  5.  19.3 16.  18.6 50.  31.6 24.1 15.6 19.4 23.3 23.2\n 13.6].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scalerX = StandardScaler().fit(X_train)\n",
    "X_train = scalerX.transform(X_train)\n",
    "X_test = scalerX.transform(X_test)\n",
    "\n",
    "scalery = StandardScaler().fit(y_train)\n",
    "y_train = scalery.transform(y_train)\n",
    "y_test = scalery.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
