{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "### LENET\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### INPUT => CONV => TANH => POOL => CONV => TANH => POOL => FC => TANH => FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.keras.optimizers import Adagrad\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet:\n",
    "    @staticmethod\n",
    "    def build(width, height, depth, classes):\n",
    "        model = Sequential()\n",
    "        inputShape = (height, width, depth)\n",
    "\n",
    "        # if using \"channels first\", update input shape\n",
    "        if K.image_data_format() == \"channel_first\":\n",
    "            inputShape = (depth, height, width)\n",
    "\n",
    "        # first set of CONV => RELU => POOL layers\n",
    "        model.add(Conv2D(20, (5, 5), padding=\"same\", input_shape=inputShape)) # 20 filters, each of size 5x5\n",
    "        model.add(Activation(\"relu\"))                                         # ReLU activation function\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))             # 2x2 pooling with 2x2 stride - decreasing input volume size by 75%\n",
    "\n",
    "        # second set of CONV => RELU => POOL layers\n",
    "        model.add(Conv2D(50, (5, 5), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "        model.add(Flatten())        # input volume is flattened\n",
    "        model.add(Dense(500))       # fully-connected layer with 500 nodes\n",
    "        model.add(Activation(\"relu\"))\n",
    "\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "\n",
    "        # return constructed network architecture\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the MNIST dataset\n",
    "print(\"[INFO] accessing MNIST...\")\n",
    "((trainData, trainLabels), (testData, testLabels)) = mnist.load_data()\n",
    "\n",
    "# if using \"channels first\" ordering, then reshape the design matrix such that the matrix is:\n",
    "# num_samples x depth x rows x columns\n",
    "if K.image_data_format() == \"channels_first\":\n",
    "\ttrainData = trainData.reshape((trainData.shape[0], 1, 28, 28))\n",
    "\ttestData = testData.reshape((testData.shape[0], 1, 28, 28))\n",
    "\n",
    "# otherwise, using \"channels last\" ordering, so the design\n",
    "# matrix shape should be: num_samples x rows x columns x depth\n",
    "else:\n",
    "\ttrainData = trainData.reshape((trainData.shape[0], 28, 28, 1))\n",
    "\ttestData = testData.reshape((testData.shape[0], 28, 28, 1))\n",
    "\n",
    "# scale data to the range of [0, 1]\n",
    "trainData = trainData.astype(\"float32\") / 255.0\n",
    "testData = testData.astype(\"float32\") / 255.0\n",
    "\n",
    "# convert the labels from integers to vectors\n",
    "le = LabelBinarizer()\n",
    "trainLabels = le.fit_transform(trainLabels)\n",
    "testLabels = le.transform(testLabels)\n",
    "\n",
    "# initialize the optimizer and model\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = SGD(lr=0.01)\n",
    "model = LeNet.build(width=28, height=28, depth=1, classes=10)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "\n",
    "# train the network\n",
    "print(\"[INFO] training network...\")\n",
    "H = model.fit(trainData, trainLabels,\n",
    "\tvalidation_data=(testData, testLabels), batch_size=128,\n",
    "\tepochs=20, verbose=1)\n",
    "\n",
    "# evaluate the network\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(testData, batch_size=128)\n",
    "print(classification_report(testLabels.argmax(axis=1),\n",
    "\tpredictions.argmax(axis=1),\n",
    "\ttarget_names=[str(x) for x in le.classes_]))\n",
    "\n",
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, 20), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, 20), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, 20), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, 20), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
